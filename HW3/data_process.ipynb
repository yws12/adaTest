{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cantons and coordinates for universities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. Here we utilize a very useful libarary `requests_cache`, which basically stores your every http requests results into a local database, default is sqlite, in order to **eliminate redundant requests**. We can use store the response for further uses because we are querying **static information**, such as locations for a place, meaning the returned results won't change during further requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import requests_cache\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "requests_cache.install_cache('ada_cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the csv file uses **semicolon** as its delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('P3_GrantExport.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract out the two columns we are concerned about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = csv_data[['University', 'Approved Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_list = data.to_dict('records')  # change dataframe to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KEY = XXX  # omit my key\n",
    "GEOCODE_URL = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "TEXT_URL = 'https://maps.googleapis.com/maps/api/place/textsearch/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_university_amount(data_list):\n",
    "    \"\"\"\n",
    "    find the total funding amount for a university \n",
    "    \n",
    "    params:\n",
    "        data_list (list): a list of dicts containing university name and amount for one project\n",
    "        \n",
    "    return:\n",
    "        universities (dict): contains university name, total amount of funding, \n",
    "                             canton of the university, latitude and longitude\n",
    "        cnt (Counter): count how many times we missed the data for one university\n",
    "    \"\"\"\n",
    "    cnt = Counter()\n",
    "    universities = {}\n",
    "    for d in data_list:\n",
    "        if isinstance(d['University'], str) and '.' in d['Approved Amount']:\n",
    "            university, amount = d['University'], float(d['Approved Amount'])\n",
    "            uni_fullname = university.split(' - ')[0]\n",
    "            if uni_fullname in universities:\n",
    "                universities[uni_fullname]['amount'] += amount\n",
    "            else:  # get university location info etco\n",
    "                text_params = {\n",
    "                    'key': KEY,\n",
    "                    'query': uni_fullname\n",
    "                }\n",
    "                text_res = requests.get(TEXT_URL, params=text_params).json()  # we use google json API\n",
    "                if text_res['status'] == 'OVER_QUERY_LIMIT':\n",
    "                    with open('universities.csv', 'w') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        for university, info in universities.items():\n",
    "                            writer.writerow([university, \n",
    "                                             \"{0:.2f}\".format(info['amount']), \n",
    "                                             info['canton'], \n",
    "                                             info['location']['lat'], \n",
    "                                             info['location']['lng']\n",
    "                                            ])\n",
    "                    return universities\n",
    "                elif text_res['status'] != 'OK':\n",
    "                    cnt[university] += 1\n",
    "                else:  # get address of text query\n",
    "                    address = text_res['results'][0]['formatted_address']  # get the first formatted address\n",
    "                    # send second request to get canton, location etc.\n",
    "                    geo_params = {\n",
    "                        'key': KEY,\n",
    "                        'address': address\n",
    "                    }\n",
    "                    geocode_res = requests.get(GEOCODE_URL, params=geo_params).json()\n",
    "                    first_res = geocode_res['results'][0]   # get the first result\n",
    "                    if 'geometry' in first_res:\n",
    "                        geometry = first_res['geometry']\n",
    "                        if 'location' not in geometry:\n",
    "                            cnt['no_location'] += 1\n",
    "                        else:\n",
    "                            universities[uni_fullname] = {\n",
    "                                'location': geometry['location'],\n",
    "                                'amount': amount,\n",
    "                                'canton': None\n",
    "                            }  # add a new university\n",
    "                            addr_comp = first_res['address_components']\n",
    "                            for addr in addr_comp:\n",
    "                                if addr['types'][0] == 'administrative_area_level_1':\n",
    "                                    universities[uni_fullname]['canton'] = addr['long_name']   #  update canton\n",
    "                    else:\n",
    "                        cnt['no_geometry'] += 1\n",
    "        else:\n",
    "            cnt['not_university'] += 1\n",
    "\n",
    "    return universities, cnt\n",
    "\n",
    "uni, c = get_university_amount(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we write a function to write the results into a csv file for futher analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def res_to_csv(universities, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['university', 'amount', 'canton', 'latitude', 'longitude'])\n",
    "        for university, info in universities.items():\n",
    "            writer.writerow([university, \n",
    "                             \"{0:.2f}\".format(info['amount']), \n",
    "                             info['canton'], \n",
    "                             info['location']['lat'], \n",
    "                             info['location']['lng']\n",
    "                            ])\n",
    "res_to_csv(uni, 'universities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the returned Counter object to see the universities whose information we can't get by Google API. The values are the number of their appearances in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Eidg. Forschungsanstalt für Wald,Schnee,Land - WSL': 223,\n",
       "         'Eidg. Material und Prüfungsanstalt - EMPA': 238,\n",
       "         'Fachhochschule Nordwestschweiz (ohne PH) - FHNW': 225,\n",
       "         'Firmen/Privatwirtschaft - FP': 492,\n",
       "         'Forschungsanstalten Agroscope - AGS': 135,\n",
       "         'Forschungskommission SAGW': 1,\n",
       "         'Haute école pédagogique BE, JU, NE - HEPBEJUNE': 7,\n",
       "         'NPO (Biblioth., Museen, Verwalt.) - NPO': 1473,\n",
       "         'Nicht zuteilbar - NA': 2595,\n",
       "         'Physikal.-Meteorolog. Observatorium Davos - PMOD': 48,\n",
       "         'Pädag. Hochschule Tessin (Teilschule SUPSI) - ASP': 2,\n",
       "         'Schweizer Kompetenzzentrum Sozialwissensch. - FORS': 30,\n",
       "         'Staatsunabh. Theologische Hochschule Basel - STHB': 3,\n",
       "         'Swiss Center for Electronics and Microtech. - CSEM': 28,\n",
       "         'Swiss Institute of Bioinformatics - SIB': 31,\n",
       "         'Weitere Institute - FINST': 43,\n",
       "         'Weitere Spitäler - ASPIT': 81,\n",
       "         'not_university': 13091})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering there are only a few missed universities, we decided to add them **manually**. Notice there are some invalid university names listed in the following:\n",
    "\n",
    "1. Firmen/Privatwirtschaft - FP, meaning private in Germany\n",
    "2. NPO (Biblioth., Museen, Verwalt.) - NPO, meaning Non-profit organization\n",
    "3. Nicht zuteilbar - NA, meaning not assgined in Germany\n",
    "4. Weitere Institute - FINST, meaning other institues in Germany\n",
    "5. Weitere Spitäler - ASPIT, meaning other hospitals in Germany\n",
    "6. not_university, meaning there's no university name or amount for this project in P3 data\n",
    "\n",
    "so we only add the rest. Plus, we find **Pädag. Hochschule Tessin** and **Forschungsanstalten Agroscope** have multiple locations and we don't know which office got the fund, so we just ignore these two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following function to calculate the total amount for each missing university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_record(university):\n",
    "    \"\"\"\n",
    "    get amount for this university\n",
    "    \n",
    "    params:\n",
    "        university (str): universitye name\n",
    "        \n",
    "    return:\n",
    "        a tuple: university and its amount\n",
    "    \"\"\"\n",
    "    university_df = data[data.University == university].copy()\n",
    "    university_df = university_df[university_df['Approved Amount'] != 'data not included in P3']\n",
    "    university_df['amount'] = university_df['Approved Amount'].astype('float')\n",
    "\n",
    "    return university, \"{0:.2f}\".format(university_df['amount'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Forschungskommission SAGW', '100000.00')\n",
      "('Swiss Center for Electronics and Microtech. - CSEM', '18068246.00')\n",
      "('Schweizer Kompetenzzentrum Sozialwissensch. - FORS', '34735816.00')\n",
      "('Haute école pédagogique BE, JU, NE - HEPBEJUNE', '627380.00')\n",
      "('Fachhochschule Nordwestschweiz (ohne PH) - FHNW', '42771914.12')\n",
      "('Physikal.-Meteorolog. Observatorium Davos - PMOD', '12098436.00')\n",
      "('Eidg. Forschungsanstalt für Wald,Schnee,Land - WSL', '48360389.63')\n",
      "('Nicht zuteilbar - NA', '142425719.57')\n",
      "('Weitere Spitäler - ASPIT', '10749808.00')\n",
      "('not_university', '0.00')\n",
      "('Weitere Institute - FINST', '9256736.00')\n",
      "('Staatsunabh. Theologische Hochschule Basel - STHB', '17300.00')\n",
      "('Swiss Institute of Bioinformatics - SIB', '11583219.00')\n",
      "('NPO (Biblioth., Museen, Verwalt.) - NPO', '334130583.79')\n",
      "('Eidg. Material und Prüfungsanstalt - EMPA', '58574515.92')\n",
      "('Pädag. Hochschule Tessin (Teilschule SUPSI) - ASP', '159317.00')\n",
      "('Forschungsanstalten Agroscope - AGS', '33115719.00')\n",
      "('Firmen/Privatwirtschaft - FP', '111686719.90')\n"
     ]
    }
   ],
   "source": [
    "for name in c.keys():\n",
    "    print(generate_record(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally we have a result csv containing **70 unique universities** of **46058 records** from original P3 data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start plotting, we check the unique cantons we get and its number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zürich          10\n",
       "Vaud             7\n",
       "Bern             6\n",
       "Ticino           6\n",
       "Valais           6\n",
       "Graubünden       5\n",
       "St. Gallen       5\n",
       "Luzern           4\n",
       "Basel-Stadt      3\n",
       "Neuchâtel        3\n",
       "Thurgau          2\n",
       "Solothurn        2\n",
       "Fribourg         2\n",
       "Aargau           2\n",
       "Schwyz           1\n",
       "Geneve           1\n",
       "Schaffhausen     1\n",
       "Zug              1\n",
       "Geneva           1\n",
       "Jura             1\n",
       "Name: canton, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('results.csv')\n",
    "results['canton'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we noticed not all canton names returned by Google are in English, some are in Germany and some in French. So we decided to use a predefined map to aggregate same canton. We also deal with the case that the info of two universities returned by Google API were not in Switzerland. In such cases, we then checked the Institutions of these two universities and found their corresponding Swiss cantons, or just remove the record if we couldn't find the Swiss institution, e.g. we remove records for university Istituto Svizzero di Roma, which is said to be in Lazio, Italy according to Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CANTON_MAP = {\n",
    "    'Sankt Gallen': 'St. Gallen',\n",
    "    'Wallis': 'Valais',\n",
    "    'Genève': 'Geneve',\n",
    "    'Geneva': 'Geneve',\n",
    "    'Baden-Württemberg': 'Valais',\n",
    "    'Hessen': 'Aargau'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_canton(x):\n",
    "    if x in CANTON_MAP:\n",
    "        return CANTON_MAP[x]\n",
    "    return x\n",
    "\n",
    "results['canton'] = results['canton'].apply(map_canton)\n",
    "results = results[results.canton != 'Lazio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zürich          10\n",
       "Vaud             7\n",
       "Bern             6\n",
       "Ticino           6\n",
       "Valais           6\n",
       "Graubünden       5\n",
       "St. Gallen       5\n",
       "Luzern           4\n",
       "Basel-Stadt      3\n",
       "Neuchâtel        3\n",
       "Geneve           2\n",
       "Thurgau          2\n",
       "Solothurn        2\n",
       "Fribourg         2\n",
       "Aargau           2\n",
       "Schwyz           1\n",
       "Schaffhausen     1\n",
       "Zug              1\n",
       "Jura             1\n",
       "Name: canton, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['canton'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write our final results to the final csv for futher analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
